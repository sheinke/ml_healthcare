{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Additional models / Hyper parameter tuning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we re-examine the data processing pipeline and create infrustructure to fit additional models. We apply grid search for hyperparameter tuning. \n",
    "\n",
    "The notebook is structured as follows:\n",
    "\n",
    "1. General dataset preparation\n",
    "2. Model input preparation\n",
    "3. Model development\n",
    "4. Hyperparameter tuning\n",
    "5. Final model \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style()\n",
    "\n",
    "# Text processing\n",
    "import nltk\n",
    "from nltk import FreqDist, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from gensim import corpora, models\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Deep learning\n",
    "import keras\n",
    "from keras import Input, Model, regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from keras.layers import Dense, Dropout, Embedding, LSTM\n",
    "from keras.engine.saving import load_model\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Data Processing Pipeline & Metrics\n",
    "from sklearn import metrics\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_curve, roc_auc_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# Miscellaneous\n",
    "import string\n",
    "import umap\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. General dataset preparation**\n",
    "\n",
    "Here we load all the data needed for the analysis and perform general transformations such as: 1) delete/examine cetain suspicious opservations 2) impute missing values  3) create new variables 4) combine test and validation sets 5) balance training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General controllers\n",
    "\n",
    "balance_data = False\n",
    "combine_train_and_val = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data\n",
    "X_train = pd.read_csv(\"../input/diab_train.csv\", index_col=0)\n",
    "\n",
    "# Validation set\n",
    "X_val = pd.read_csv(\"../input/diab_validation.csv\", index_col=0)\n",
    "Y_val = X_val[\"readmitted\"]\n",
    "len_val = len(X_val)\n",
    "\n",
    "# Test set\n",
    "X_test  = pd.read_csv(\"../input/diab_test.csv\", index_col=0)\n",
    "Y_test = X_test[\"readmitted\"]\n",
    "len_test = len(X_test)\n",
    "\n",
    "# Combine all together\n",
    "X_Y_all = pd.concat([X_train, X_val, X_test]).reset_index(drop=True)\n",
    "X_Y_all[\"partition\"] = np.concatenate([np.repeat(\"train\", len(X_train)), np.repeat(\"val\", len(X_val)), np.repeat(\"test\", len(X_test))])\n",
    "\n",
    "# Drop Y from X_test. We will do the same for X_train, and X_val after we balance the data\n",
    "X_test = X_test.drop(columns=\"readmitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1:** delete/examine some strange observations. \n",
    "\n",
    "\n",
    "During the dataset exploration we have discovered data subjects, that could be irrelevant for our analysis. We are considering two approaches to handle these cases:\n",
    "\n",
    "* delete these cases from the training set (if there is nothing similiar in validation/test) sets\n",
    "* treat certain \"unusual\" attributes as missing data\n",
    "\n",
    "\n",
    "**Suspicious case 1**\n",
    "\n",
    "1 newborn, who was later not readmitted, such cases do not exist in validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>partition</th>\n",
       "      <th>readmitted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3197</th>\n",
       "      <td>train</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     partition  readmitted\n",
       "3197     train           0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_Y_all.loc[X_Y_all['admission_type_id'] == \"Newborn\", [\"partition\", 'readmitted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "his diagnosis was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diverticulosis of small intestine (without mention of hemorrhage)\n",
      "Congestive heart failure, unspecified\n",
      "Diabetes with ophthalmic manifestations, type II or unspecified type, uncontrolled\n"
     ]
    }
   ],
   "source": [
    "txt1 = X_Y_all.loc[X_Y_all['admission_type_id'] == \"Newborn\", 'diag_1_desc'].values[0]\n",
    "txt2 = X_Y_all.loc[X_Y_all['admission_type_id'] == \"Newborn\", 'diag_2_desc'].values[0]\n",
    "txt3 = X_Y_all.loc[X_Y_all['admission_type_id'] == \"Newborn\", 'diag_3_desc'].values[0]\n",
    "\n",
    "diagn = \"{}\\n{}\\n{}\".format(txt1, txt2, txt3)\n",
    "print(diagn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This observation appears to be relevant, yet it creates a challenge for treating `admission_type_id` as an ordered variable. I would propose to encode it as a missing value and re-impute it later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.loc[X_train['admission_type_id'] == \"Newborn\", 'admission_type_id'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 2:** missing values imputation\n",
    "\n",
    "When dealing with missing values we have three main options\n",
    "\n",
    "1. use an algorithm to impute missing values \n",
    "2. encode missing value as a separate category, or assign certain value\n",
    "3. exclude the variable from the subsequent analysis \n",
    "\n",
    "We would like to take a look at the structure of missingness in the data. Our objective is to do a preliminary check, whether we can observe a pattern. \n",
    "\n",
    "Three situations might take place:\n",
    "\n",
    "* Missing completely at random (MCAR)\n",
    "* Missing at random (MAR)\n",
    "* Missing not at random (MNAR)\n",
    "\n",
    "In case **MCAR** and **MAR** it is reasonable to try to impute missing values, whereas in case **MNAR** and procedure might lead to biases, therefore at least for categorical variables, it would be reasonable to eoncode this state separately or entirely exclude them from the analysis\n",
    "\n",
    "\n",
    "The code at the beginning of the `readmission_prediction` notebook  allows us to examine unique values of different variables. Based on this we have concluded that the following entries (alongsize with standard np.nan) encodes the fact that the variable is missing\n",
    "\n",
    "**Comment** some visualizations can be found in the notebook `readmission_prediction.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_symbols = ['?', 'None','Not Available', 'Not Mapped'] # [\"\", \" \", 'NaN'] # - adding does not change the numbers\n",
    "\n",
    "for val in missing_symbols:\n",
    "    X_train = X_train.replace(val, np.nan)\n",
    "    X_val = X_val.replace(val, np.nan)\n",
    "    X_test = X_test.replace(val, np.nan)\n",
    "\n",
    "# list variables with predominantly missing values\n",
    "missing_threshold = 0.4  \n",
    "\n",
    "missing_value = X_train.apply(lambda x: sum(x.isnull())/len(X_train) ).sort_values(ascending=False)\n",
    "mostly_missing = list(missing_value[missing_value > missing_threshold].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preliminary pragmatic solution is to:** \n",
    "\n",
    "1. exclude variables `weight`, `max_glu_serum`, `A1Cresult` from the analysis\n",
    "2. encode `payer_code`, `medical_specialty`, `discharge_disposition_id`, `diag_1(2,3)_desc` as a separate level\n",
    "3. impute missing values for `admission_type_id`, `admission_source_id` and `race`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_delete = [\"weight\", \"max_glu_serum\", \"A1Cresult\"]\n",
    "\n",
    "vars_to_reencode =  [\"payer_code\", \"medical_specialty\", \"discharge_disposition_id\", \n",
    "                     \"diag_1_desc\", \"diag_2_desc\", \"diag_3_desc\"]\n",
    "\n",
    "vars_to_impute = [\"admission_type_id\", \"admission_source_id\", \"race\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in vars_to_reencode:\n",
    "    \n",
    "    X_train[var] = X_train[var].replace(np.nan, \" \")\n",
    "    X_test[var] = X_test[var].replace(np.nan, \" \")\n",
    "    X_val[var] = X_val[var].replace(np.nan, \" \")\n",
    "    \n",
    "assert(any(X_train[vars_to_reencode].isnull().any()) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impute missing values**\n",
    "\n",
    "We use a [SimpleImputer](https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html) to fill in the missing values\n",
    "\n",
    "**Note:** We have tried to perform [multivariate feature imputation](https://scikit-learn.org/stable/modules/impute.html), however current implementation of the algorithm does not work with categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "X_train[vars_to_impute] = imp.fit_transform(X_train[vars_to_impute])\n",
    "# No information leaking -> fit on train, and use this transformation on everything else\n",
    "X_val[vars_to_impute] = imp.transform(X_val[vars_to_impute])\n",
    "X_test[vars_to_impute] = imp.transform(X_test[vars_to_impute])\n",
    "\n",
    "assert(any(X_train[vars_to_impute].isnull().any()) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 3:** create new variables\n",
    "\n",
    "We do some small feature engineering. This step is not vital in the deep learning framework, however it might be relevant for dealing with **ordinal** variables. \n",
    "\n",
    "For **ordinal** variables, we have decided to perform integer mapping and treat them as numeric values later. This is not an optimal approach since this assumes that the distance between different categories is the same. To be more precise this is a valid assumption for `age` and `weight` since \"[10-20] - [0-10)\" $\\approx$ \"[30-40] - [20-30)\", however the same does not necessarily hold for `admission_type_id` with *Emergency* - *Urgent* $\\geq ? \\leq$ *Urgent* - *Elective*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_encode_dict = {\"[0-10)\":1, \"[10-20)\":2, \"[20-30)\":3, \"[30-40)\":4, \n",
    "                   \"[40-50)\":5, \"[50-60)\":6, \"[60-70)\":7, \"[70-80)\":8,\n",
    "                   \"[80-90)\":9, \"[90-100)\":10 }\n",
    "\n",
    "admission_type_dict = {\"Elective\":1, \"Urgent\":2, \"Emergency\":3}\n",
    "\n",
    "\n",
    "def encode_variables(var_category:str, category_dict=age_encode_dict):\n",
    "    \"\"\"\n",
    "    >>> encode_variables(\"[0-10)\")\n",
    "    \"\"\"\n",
    "    return category_dict.get(var_category, np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[\"age_category\"] = X_train[\"age\"].apply(encode_variables)\n",
    "X_train[\"admission_type_id_category\"] = X_train[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "\n",
    "X_val[\"age_category\"] = X_val[\"age\"].apply(encode_variables)\n",
    "X_val[\"admission_type_id_category\"] = X_val[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "\n",
    "X_test[\"age_category\"] = X_test[\"age\"].apply(encode_variables)\n",
    "X_test[\"admission_type_id_category\"] = X_test[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "\n",
    "\n",
    "assert(any(X_train[[\"age_category\", \"admission_type_id_category\"]].isnull().any()) == False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 4:** combine test and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if combine_train_and_val:\n",
    "    X_train = pd.concat([X_train, X_val]).reset_index(drop=True)\n",
    "else:\n",
    "    X_val = X_val.drop(columns=\"readmitted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 5:** balance training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if balance_data:\n",
    "    positives = X_train[X_train[\"readmitted\"] == 1]\n",
    "    negatives = X_train[X_train[\"readmitted\"] == 0]\n",
    "    oversampled = positives.sample(int(0.5 * len(X_train) - len(positives)), replace=True)\n",
    "    undersampled = negatives.sample(int(0.5 * len(X_train)), replace=True)\n",
    "    X_train = pd.concat([positives, oversampled, undersampled]).reset_index(drop=True)\n",
    "    \n",
    "try: # error is raised by running this cell twice\n",
    "    Y_train = X_train[\"readmitted\"]\n",
    "    X_train = X_train.drop(columns=\"readmitted\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **All together**\n",
    "\n",
    "the function below combines all the steps from the described pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_delete = [\"weight\", \"max_glu_serum\", \"A1Cresult\"]\n",
    "vars_to_reencode =  [\"payer_code\", \"medical_specialty\", \"discharge_disposition_id\", \n",
    "                     \"diag_1_desc\", \"diag_2_desc\", \"diag_3_desc\"]\n",
    "vars_to_impute = [\"admission_type_id\", \"admission_source_id\", \"race\", \"age\"]\n",
    "missing_symbols = ['?', 'None','Not Available', 'Not Mapped']\n",
    "\n",
    "\n",
    "\n",
    "def data_loading_preprocessing(balance_data=False,\n",
    "                               combine_train_and_val=False,\n",
    "                               encode_as_missing=True,\n",
    "                               missing_symbols=missing_symbols,\n",
    "                               vars_to_delete=vars_to_delete,\n",
    "                               vars_to_reencode=vars_to_reencode,\n",
    "                               vars_to_impute=vars_to_impute ):\n",
    "    \"\"\"\n",
    "    Usage/Testing\n",
    "    >>> X_train, Y_train, X_val, Y_val, X_test, Y_test = data_loading_preprocessing()\n",
    "    \"\"\"\n",
    "    # Training data\n",
    "    X_train = pd.read_csv(\"../input/diab_train.csv\", index_col=0)\n",
    "    # Validation set\n",
    "    X_val = pd.read_csv(\"../input/diab_validation.csv\", index_col=0)\n",
    "    Y_val = X_val[\"readmitted\"]\n",
    "    # Test set\n",
    "    X_test  = pd.read_csv(\"../input/diab_test.csv\", index_col=0)\n",
    "    Y_test = X_test[\"readmitted\"]\n",
    "\n",
    "    # Drop Y from X_test. We will do the same for X_train, and X_val after we balance the data\n",
    "    X_test = X_test.drop(columns=\"readmitted\")\n",
    "    X_train.loc[X_train['admission_type_id'] == \"Newborn\", 'admission_type_id'] = np.nan\n",
    "    \n",
    "    # Replace variables in \"missing symbols\" by np.nan\n",
    "    if encode_as_missing:\n",
    "        for val in missing_symbols:\n",
    "            X_train = X_train.replace(val, np.nan)\n",
    "            X_val = X_val.replace(val, np.nan)\n",
    "            X_test = X_test.replace(val, np.nan)\n",
    "\n",
    "    for var in vars_to_reencode:\n",
    "\n",
    "        X_train[var] = X_train[var].replace(np.nan, \" \")\n",
    "        X_test[var] = X_test[var].replace(np.nan, \" \")\n",
    "        X_val[var] = X_val[var].replace(np.nan, \" \")\n",
    "\n",
    "    assert(any(X_train[vars_to_reencode].isnull().any()) == False)\n",
    "\n",
    "    imp = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "\n",
    "    X_train[vars_to_impute] = imp.fit_transform(X_train[vars_to_impute])\n",
    "    # No information leaking -> fit on train, and use this transformation on everything else\n",
    "    X_val[vars_to_impute] = imp.transform(X_val[vars_to_impute])\n",
    "    X_test[vars_to_impute] = imp.transform(X_test[vars_to_impute])\n",
    "\n",
    "    assert any(X_train[vars_to_impute].isnull().any()) == False, \"problem with missing variable imputation\"\n",
    "\n",
    "    X_train[\"age_category\"] = X_train[\"age\"].apply(encode_variables)\n",
    "    X_train[\"admission_type_id_category\"] = X_train[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "\n",
    "    X_val[\"age_category\"] = X_val[\"age\"].apply(encode_variables)\n",
    "    X_val[\"admission_type_id_category\"] = X_val[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "\n",
    "    X_test[\"age_category\"] = X_test[\"age\"].apply(encode_variables)\n",
    "    X_test[\"admission_type_id_category\"] = X_test[\"admission_type_id\"].apply(lambda x: encode_variables(x, admission_type_dict))\n",
    "    \n",
    "    assert(any(X_train[[\"age_category\", \"admission_type_id_category\"]].isnull().any()) == False)\n",
    "\n",
    "    if combine_train_and_val:\n",
    "        X_train = pd.concat([X_train, X_val]).reset_index(drop=True)\n",
    "    else:\n",
    "        X_val = X_val.drop(columns=\"readmitted\")\n",
    "\n",
    "    if balance_data:\n",
    "        positives = X_train[X_train[\"readmitted\"] == 1]\n",
    "        negatives = X_train[X_train[\"readmitted\"] == 0]\n",
    "        oversampled = positives.sample(int(0.5 * len(X_train) - len(positives)), replace=True)\n",
    "        undersampled = negatives.sample(int(0.5 * len(X_train)), replace=True)\n",
    "        X_train = pd.concat([positives, oversampled, undersampled]).reset_index(drop=True)\n",
    "\n",
    "    Y_train = X_train[\"readmitted\"]\n",
    "    X_train = X_train.drop(columns=\"readmitted\")\n",
    "    \n",
    "    return X_train, Y_train, X_val, Y_val, X_test, Y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Input Preparation**\n",
    "\n",
    "After cleaning the dataset, we work with individual variables. Variables in the dataset can be divided into several groups: **Numeric**, **Categorical** and **Textual**. Each subgroup requires individual approach furthermore feature transformation can differ depending on the selected neural network architecture. This and other aspects will be discussed below.\n",
    "\n",
    "\n",
    "Our choices are informed by the plots in `readmission_prediction.ipynb`. Most of the functions below are modified/extended versions of the feature preprocessing introduced in `models_final.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Numeric input**\n",
    "\n",
    "Numeric input preprocessing comprises the following steps\n",
    "\n",
    "1. **Variable transformation:** upon examining histrograms and scatter plots of numeric variables we have noticed that variables `number_outpatient`, `number_emergency` have a couple of outlier values $\\Rightarrow$ might want to reduce their influence by transforming the variables.\n",
    "\n",
    "2. **Normalization.**  Normalization is performed using values of the *training* set only, to transform  *test* and *validation* set we pass the normalizer fitted on the training data as a function argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = [\"time_in_hospital\", \"num_procedures\", \n",
    "                      \"number_outpatient\", \"number_emergency\", \n",
    "                      \"number_inpatient\", \"number_diagnoses\",\n",
    "                      \"num_medications\", \"num_lab_procedures\",\n",
    "                      # add integer encoded ordinal variables\n",
    "                      \"age_category\", \"admission_type_id_category\"\n",
    "                     ]\n",
    "\n",
    "\n",
    "\n",
    "sqrt_transform_features = [\"number_outpatient\", \"number_emergency\"]\n",
    "\n",
    "def get_numerical_inputs(df_in: pd.DataFrame, \n",
    "                         numerical_features = numerical_features,\n",
    "                         sqrt_transform_features = sqrt_transform_features,\n",
    "                         normalizer = None\n",
    "                        ):\n",
    "\n",
    "    df = df_in.copy()\n",
    "    \n",
    "    # some columns have extreme values:\n",
    "    for var in sqrt_transform_features:\n",
    "        df[var] = df[var].apply(lambda x: np.sqrt(x + 0.5))\n",
    "\n",
    "    if normalizer == None:\n",
    "        normalizer = Pipeline([(\"normalize\", StandardScaler())])\n",
    "        numerical_inputs = normalizer.fit_transform(df[numerical_features])\n",
    "        \n",
    "    else:\n",
    "        numerical_inputs = normalizer.transform(df[numerical_features])\n",
    "    \n",
    "    return numerical_inputs, normalizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Categorical input**\n",
    "\n",
    "Dataset contains various categorical features, which we have divided into the following 3 groups:  \n",
    "\n",
    "* **medications**: **23** variables corresponding to different treatments prescribed to patients \n",
    "* **diagnostics code**: ICD9 codes of the patient's primary (secondary) diagnosis in \n",
    "* **general** contain different categorical features that do not require specific preprocessing steps apart from One Hot encoding\n",
    "\n",
    "#### **General features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"race\", \"gender\", \n",
    "                        \n",
    "                        # \"age\",  \"admission_type_id\",     # used in the model as age_category and  admission_type_id_category\n",
    "                        #\"max_glu_serum\", \"A1Cresult\",     # delete due too many missing variables\n",
    "\n",
    "                        \"payer_code\", \"medical_specialty\",  # a lot of missing values, exclude?\n",
    "                        \n",
    "                        \"change\", \"diabetesMed\", \n",
    "                        \"admission_source_id\", \n",
    "                        \"discharge_disposition_id\"]\n",
    "\n",
    "\n",
    "def get_categorical_inputs(df_in: pd.DataFrame,\n",
    "                           categorical_features=categorical_features,\n",
    "                           encoder=None):\n",
    "    \"\"\"\n",
    "    Usage\n",
    "    >>> input_categ, enc = get_categorical_inputs(X_train)\n",
    "    >>> input_categ_test, _ = get_categorical_inputs(X_train, encoder=enc)\n",
    "    \"\"\"\n",
    "    df = df_in.copy()\n",
    "        \n",
    "    # admission_source_id and discharge_disposition_id are heavily imbalanced\n",
    "    # and increase the input dimension too much:\n",
    "    admi_type_id_keep = [\"Emergency Room\", \"Physician Referral\", 'Transfer from a hospital', 'Transfer from another health care facility']\n",
    "    df[~df.admission_source_id.isin(admi_type_id_keep)] = \"other\"\n",
    "    dis_dis_id_keep = ['Discharged to home', 'Discharged/transferred to SNF', 'Discharged/transferred to home with home health service']\n",
    "    df[~df.discharge_disposition_id.isin(dis_dis_id_keep)] = \"other\"\n",
    "\n",
    "    if encoder == None:\n",
    "        encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "        categorical_inputs = encoder.fit_transform(df[categorical_features]).toarray()\n",
    "    else:\n",
    "        categorical_inputs = encoder.transform(df[categorical_features]).toarray()\n",
    "    \n",
    "    return categorical_inputs, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Information about medications**\n",
    "\n",
    "This group of variables is preprocessed as follows:\n",
    "\n",
    "1. **Input selection**. Plots in`readmission_prediction.ipynb` indicate that most of the drugs are prescribed extremely rarely (to less than 10% of the patients) $\\Rightarrow$ use information from the *training* set to exclude the rarest drugs.\n",
    "\n",
    "2. **Input encoding** Variables in this category can take 4 values: \"No\", \"Steady\", \"Up\", \"Down\", whereby the majority is \"No\". We experiment with two types of encodings: a) 0 - \"No\" vs 1 - any other b) 0 - \"No\", 1 - \"Steady\", 2 - \"Up\", 3 - \"Down\"\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "medicine_all = [\"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\", \"glimepiride\", \n",
    "                \"acetohexamide\", \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \n",
    "                \"acarbose\", \"miglitol\", \"troglitazone\", \"tolazamide\", \"examide\", \"citoglipton\", \"insulin\", \n",
    "                \"glyburide.metformin\", \"glipizide.metformin\", \"glimepiride.pioglitazone\", \n",
    "                \"metformin.rosiglitazone\", \"metformin.pioglitazone\"]\n",
    "\n",
    "\n",
    "def get_medicine_inputs(df_in: pd.DataFrame, \n",
    "                        medicine_all = medicine_all,\n",
    "                        perc_no_values_thresold = None,\n",
    "                        medicine_to_return = None,\n",
    "                        is_binary_output = True,\n",
    "                        encoder = None,\n",
    "                       ):\n",
    "    \"\"\"\n",
    "    :param perc_no_values_thresold  if the percentage of missing values exceeds this \n",
    "                                    threshold -> exclude it from the subsequent analysis\n",
    "                                    \n",
    "    :param is_binary_output:        if yes, encode as a binary variable\n",
    "    \n",
    "    Usage/Testing:\n",
    "    >>> med_input, medicine_thresh, encoder = get_medicine_inputs(X_train, perc_no_values_thresold=0.95)\n",
    "    >>> med_input_test, _, _ = get_medicine_inputs(X_test, medicine_to_return=medicine_thresh )\n",
    "    \n",
    "    \"\"\"\n",
    "    if (medicine_to_return == None) and (perc_no_values_thresold==None):\n",
    "        # Need to ensure that the list of medicines is the same for train, test and validate datasets !\n",
    "        print(\"You need to provide either perc_no_values_thresold or a list of drugs to return\")\n",
    "        raise Exception\n",
    "    \n",
    "    df = df_in.copy()\n",
    "    # categorical: {up, down, steady, no}\n",
    "\n",
    "    if medicine_to_return==None:\n",
    "        # the histograms show that for majority of medicine there is little information\n",
    "        medicine_to_return = []\n",
    "        for med in medicine_all:\n",
    "            perc_no_values = (df[med]==\"No\").sum() / df.shape[0]\n",
    "            if perc_no_values < perc_no_values_thresold:  # 90% leaves 4 medicines\n",
    "                medicine_to_return.append(med)\n",
    "\n",
    "        print(\"{} drugs left (out of {}) after filtering with threshold {}: \\n\".format(len(medicine_to_return), len(medicine_all), perc_no_values_thresold))\n",
    "    \n",
    "    \n",
    "    if is_binary_output:\n",
    "        to_binary = FeatureModifier(features=medicine_to_return, func=(lambda x: 0 if x == \"No\" else 1))\n",
    "        medicine_inputs = to_binary.transform(df)\n",
    "        enc = None\n",
    "    \n",
    "    else:  \n",
    "        if encoder == None:\n",
    "            encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "            medicine_inputs = encoder.fit_transform(df_in[medicine_to_return])\n",
    "        else:\n",
    "            medicine_inputs = encoder.transform(df_in[medicine_to_return])\n",
    "    \n",
    "    return medicine_inputs, medicine_to_return, encoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Diagnosis code**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ICD9_to_class (x):\n",
    "    x = str(x)\n",
    "    try:\n",
    "        if(x.startswith(\"E\")):\n",
    "            return 0\n",
    "        if(x.startswith(\"V\")):\n",
    "            return 1\n",
    "        if x.split(\".\")[0] == \"?\":\n",
    "            return 0\n",
    "        if str(x) == 'nan':\n",
    "            return 0\n",
    "        if x == np.nan:\n",
    "            return 0\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    breakpoints = [0, 140, 240, 280, 290, 320, 390, 460, 520, 580, 630, 680, 710, 740, 760, 780, 800]\n",
    "    breakpoints.reverse()\n",
    "    class_nr = len(breakpoints) - 1\n",
    "    for bp in breakpoints:\n",
    "        if int(x.split(\".\")[0]) >= bp:\n",
    "            return class_nr\n",
    "        class_nr = class_nr - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_codes = [\"diag_1\", \"diag_2\", \"diag_3\"]\n",
    "        \n",
    "def get_diags_inputs(df_in: pd.DataFrame,\n",
    "                     diagnosis_codes=diagnosis_codes):\n",
    "    \"\"\"this version combines all three diagnosis in one vector, using the OR-function\"\"\"\n",
    "    df = df_in.copy()\n",
    "    diag_in_classes = df[diagnosis_codes].applymap(map_ICD9_to_class)\n",
    "    max_class_num = diag_in_classes.values.max()\n",
    "    diags_inputs = np.zeros((len(df), max_class_num + 1))\n",
    "    for index, row in diag_in_classes.iterrows():\n",
    "        diags_inputs[index, row[\"diag_1\"]] = 1\n",
    "        diags_inputs[index, row[\"diag_2\"]] = 1\n",
    "        diags_inputs[index, row[\"diag_3\"]] = 1\n",
    "    \n",
    "    return diags_inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Textual input**\n",
    "\n",
    "Our goal is to include the variables `diag_1_desc`,  `diag_2_desc` and  `diag_3_desc` in the model.\n",
    "\n",
    "We have considered the following options to represent the sentence:\n",
    "\n",
    "* every sentence is a tockenized and encoded as a sequence of integers with a fixed length `max_len` (get_model_lstm_own_embedding)\n",
    "* every sentence is represented by a matrix with dimension `max_len` x `embedding_size`. This representation can be obtained by i.e. **Word2Vec** (get_model_lstm_embedding_ready)\n",
    "* every sentence is represented by a vector of a fixed size. This representation can be obtained by i.e. **tf-idf** or **word2doc** (get_model_tfdif)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we perform some basic preprocessing of the text, consisting of **word tokenization**, **normalization**, **stemming**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select features\n",
    "class Selector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "\n",
    "# impute missing values\n",
    "class MissingChanger(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, constant):\n",
    "        self.features = features\n",
    "        self.constant = constant\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.features].fillna(self.constant)\n",
    "\n",
    "# apply function to some features\n",
    "class FeatureModifier(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features, func):\n",
    "        self.features = features\n",
    "        self.func = func\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        Xnew = X.copy()[self.features]\n",
    "        Xnew = Xnew[self.features].applymap(lambda x: self.func(x))\n",
    "        return np.array(Xnew)\n",
    "    \n",
    "# textual transformations\n",
    "class TokenizerOur(BaseEstimator, TransformerMixin): # there is a naming conflict due to keras.preprocessing.text.Tokenizer\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.applymap(lambda x: word_tokenize(x))\n",
    "   \n",
    "\n",
    "class StopWordsFilter(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stopwords = stopwords.words('english') + list(string.punctuation)\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.applymap(lambda x: [word for word in x if word not in self.stopwords])\n",
    "\n",
    "    \n",
    "class Stemmer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.stemmer = PorterStemmer()\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X.applymap(lambda x: [self.stemmer.stem(word) for word in x])\n",
    "\n",
    "    \n",
    "class ToStringList(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, features_to_group):\n",
    "        self.features_to_group = features_to_group \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        string_list = []\n",
    "        for index, row in X.iterrows():\n",
    "            entry = []\n",
    "            for feat in self.features_to_group:\n",
    "                entry.extend(row[feat])\n",
    "            string_list.append(\" \".join(entry))\n",
    "        return string_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_descriptions = [\"diag_1_desc\", \"diag_2_desc\", \"diag_3_desc\"]\n",
    "\n",
    "textual_preprocessing_pipeline = Pipeline([\n",
    "        (\"select_textual_features\", Selector(diagnosis_descriptions)),\n",
    "        (\"add_missing_class\", MissingChanger(diagnosis_descriptions, \"\")),\n",
    "        (\"tokenize\", TokenizerOur()),\n",
    "        (\"filter_stop_words\", StopWordsFilter()),\n",
    "        (\"perform_stemming\", Stemmer()),\n",
    "    ])\n",
    "\n",
    "# do not exclude stop words\n",
    "textual_preprocessing_pipeline_short = Pipeline([\n",
    "    (\"select_textual_features\", Selector(diagnosis_descriptions)),\n",
    "    (\"tokenize\", TokenizerOur()),\n",
    "    (\"perform_stemming\", Stemmer())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Get a tockenized sentence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------ IMPORTANT CONSTANTS: (change later)\n",
    "#textual_preprocessing_pipeline_short\n",
    "\n",
    "def get_tockenized_sentence(df: pd.DataFrame,\n",
    "                            train=False,\n",
    "                            tokenizer=None,\n",
    "                            num_words_tockenize = 500, #num_words_tockenize,\n",
    "                            max_sentence_len = 25,#max_sentence_len,\n",
    "                            pipeline = textual_preprocessing_pipeline\n",
    "                           ):\n",
    "    \"\"\"\n",
    "    :param train: sentences in X_train and all the other datasets should be transformed using the same tockenizer, \n",
    "                  othersize the representation might not be useful for prediction\n",
    "\n",
    "                  train = true: train the tokinizer on the df\n",
    "                  train = false: transform the text from the df using the provided tokenizer\n",
    "                  \n",
    "    :param num_words_tockenize\n",
    "                  the maximum number of words to keep, based on word frequency. \n",
    "                  Only the most common num_words-1 words will be kept.\n",
    "                  \n",
    "    :param max_sentence_len\n",
    "                  after the preprocessing most of the diagnosis are no longer than\n",
    "                  25 words, therefore the value probably should not exceed 25\n",
    "                  \n",
    "    :return:      for each diagnosis we get a sequence of integers, padded with 0\n",
    "                  of total length `max_sentence_len`\n",
    "    \n",
    "    Usage:\n",
    "    >>> diag1, diag2, diag3, tockinizer_train = get_tockenized_sentence( X_train, train=True )\n",
    "    >>> diag1_tst, diag2_tst, diag3_tst, _ = get_tockenized_sentence( X_test, train=False, tockenizer=tockinizer_train )\n",
    "    \"\"\"\n",
    "    if (not train) and tokenizer==None:\n",
    "        print(\"Need either to train a model or to provide a tockenizer\")\n",
    "        raise Exception\n",
    "    \n",
    "    # Replace missing values (should be redundand now due to step 3 in data preprocessing section)\n",
    "    df[\"diag_1_desc\"] = df[\"diag_1_desc\"].replace(np.nan, \" \")\n",
    "    df[\"diag_2_desc\"] = df[\"diag_2_desc\"].replace(np.nan, \" \")\n",
    "    df[\"diag_3_desc\"] = df[\"diag_3_desc\"].replace(np.nan, \" \")\n",
    "\n",
    "    # prepare all text information \n",
    "    # as a result, a sentence is an array of key words\n",
    "    if tokenizer == None:\n",
    "        df_transformed = textual_preprocessing_pipeline.fit_transform(df)\n",
    "    else:\n",
    "        df_transformed = textual_preprocessing_pipeline.transform(df)\n",
    "    df_transformed_all = np.concatenate([df_transformed[feature].values for feature in diagnosis_descriptions])\n",
    "   \n",
    "    \n",
    "    # represent a sentence as  a sequence of integers\n",
    "    if tokenizer == None:\n",
    "        tokenizer = text.Tokenizer(num_words=num_words_tockenize)\n",
    "        tokenizer.fit_on_texts(df_transformed_all)\n",
    "\n",
    "    vocab_size = len(tokenizer.word_index) + 1 \n",
    "    #print(\"Vocabulary size for the diagnosis is: {}\".format(vocab_size))\n",
    "\n",
    "    # Encode text to sequence\n",
    "    inp_nlp_diag1 = tokenizer.texts_to_sequences( list(df_transformed[\"diag_1_desc\"].values) ) \n",
    "    inp_nlp_diag2 = tokenizer.texts_to_sequences( list(df_transformed[\"diag_2_desc\"].values) )\n",
    "    inp_nlp_diag3 = tokenizer.texts_to_sequences( list(df_transformed[\"diag_3_desc\"].values) ) \n",
    "\n",
    "    # Pad to achieve the desired sequence length\n",
    "    inp_nlp_diag1_fin = pad_sequences(inp_nlp_diag1, maxlen = max_sentence_len, padding=\"post\")\n",
    "    inp_nlp_diag2_fin = pad_sequences(inp_nlp_diag2, maxlen = max_sentence_len, padding=\"post\")\n",
    "    inp_nlp_diag3_fin = pad_sequences(inp_nlp_diag3, maxlen = max_sentence_len, padding=\"post\")\n",
    "    \n",
    "    return inp_nlp_diag1_fin, inp_nlp_diag2_fin, inp_nlp_diag2_fin, tokenizer, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Get an embedded sentence**\n",
    "\n",
    "We use a word embedding algorithm to represent all the sentences as matrices of potentially fixed length. \n",
    "\n",
    "**NB** we are not certain whether it would be really different from just feeding a tokenized sentence to an Embedding layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_sentence(df,\n",
    "                          pipeline = textual_preprocessing_pipeline,\n",
    "                          w2v_embedding_size = 30,\n",
    "                          embed_model = None,\n",
    "                          max_sent_len = 6\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    >>> inp_mtr_1, inp_mtr_2, inp_mtr_3, embed_model = get_embedded_sentence(X_train)\n",
    "    >>> inp_mtr_1, inp_mtr_2, inp_mtr_3, embed_model = get_embedded_sentence(X_train, embed_model=embed_model)\n",
    "    \"\"\"\n",
    "    \n",
    "    transformed_text = pipeline.fit_transform(df)\n",
    "    transformed_text_all = np.concatenate([transformed_text[feature].values for feature in diagnosis_descriptions])\n",
    "\n",
    "    if embed_model==None:\n",
    "        embed_model = Word2Vec(transformed_text_all, \n",
    "                               size=w2v_embedding_size,          # Dimensionality of the word vectors.\n",
    "                               min_count=1)        # Ignores all words with total frequency lower than this.\n",
    "\n",
    "    #----------- Initialize 3 embedding matrices for all 3 input variables\n",
    "    df_size = df.shape[0]\n",
    "    problem_words = []\n",
    "    \n",
    "    inp_mtr_1 = np.zeros(( df_size, max_sent_len, w2v_embedding_size ))\n",
    "    inp_mtr_2 = np.zeros(( df_size, max_sent_len, w2v_embedding_size ))\n",
    "    inp_mtr_3 = np.zeros(( df_size, max_sent_len, w2v_embedding_size ))\n",
    "    \n",
    "    cnt = 0\n",
    "    for i in range(df_size):\n",
    "        for j in range(max_sent_len):\n",
    "            if len( transformed_text.loc[i, 'diag_1_desc'] ) > j:\n",
    "                cnt+=1\n",
    "                try:\n",
    "                    inp_mtr_1[i, j, :] = embed_model.wv[transformed_text.loc[i, 'diag_1_desc'][j]]\n",
    "                except Exception as e:\n",
    "                    # encode with 1 all out of vocabulary words\n",
    "                    #print(e)\n",
    "                    inp_mtr_1[i, j, :] = np.ones(w2v_embedding_size)\n",
    "                    problem_words.append(transformed_text.loc[i, 'diag_1_desc'][j])\n",
    "            else:\n",
    "                inp_mtr_1[i, j, :] = np.zeros(w2v_embedding_size)\n",
    "                \n",
    "    for i in range(df_size):\n",
    "        for j in range(max_sent_len):\n",
    "            if len( transformed_text.loc[i, 'diag_2_desc'] ) > j:\n",
    "                cnt+=1\n",
    "                try:\n",
    "                    inp_mtr_2[i, j, :] = embed_model.wv[transformed_text.loc[i, 'diag_2_desc'][j]]\n",
    "                except Exception as e:\n",
    "                    # encode with 1 all out of vocabulary words\n",
    "                    #print(e)\n",
    "                    inp_mtr_2[i, j, :] = np.ones(w2v_embedding_size)\n",
    "                    problem_words.append(transformed_text.loc[i, 'diag_2_desc'][j])\n",
    "            else:\n",
    "                inp_mtr_2[i, j, :] = np.zeros(w2v_embedding_size)\n",
    "    \n",
    "    \n",
    "    for i in range(df_size):\n",
    "        for j in range(max_sent_len):\n",
    "            if len( transformed_text.loc[i, 'diag_3_desc'] ) > j:\n",
    "                cnt+=1\n",
    "                try:\n",
    "                    inp_mtr_3[i, j, :] = embed_model.wv[transformed_text.loc[i, 'diag_3_desc'][j]]\n",
    "                except Exception as e:\n",
    "                    # encode with 1 all out of vocabulary words\n",
    "                    #print(e)\n",
    "                    inp_mtr_3[i, j, :] = np.ones(w2v_embedding_size)\n",
    "                    problem_words.append(transformed_text.loc[i, 'diag_3_desc'][j])\n",
    "            else:\n",
    "                inp_mtr_3[i, j, :] = np.zeros(w2v_embedding_size)\n",
    "\n",
    "    print(\"{} out of {} words could not be encoded\".format(len(problem_words), cnt))    \n",
    "    \n",
    "    return inp_mtr_1, inp_mtr_2, inp_mtr_3, embed_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Sencence as vector**\n",
    "\n",
    "Every diagnosis is represented as a vector of a fixed size. We implement the following too approaches to get this representation:\n",
    "\n",
    "1. every sentence is a row in the matrix of TF-IDF features (from `models_final.ipynb`)\n",
    "2. every sentence is the average of the **word2vec** representations of the terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diags_descs_tfidf(df: pd.DataFrame,\n",
    "                          diags_descs_to_tfidf=None,\n",
    "                          min_df=400, \n",
    "                          max_df=None):\n",
    "    \"\"\"\n",
    "    Convert a collection of all diagnoses to a matrix of TF-IDF features.\n",
    "    \n",
    "    Usage / Testing\n",
    "    >>> inputs_textual, to_idf = get_diags_descs_tfidf(X_train)\n",
    "    >>> inputs_textual, _ = get_diags_descs_tfidf(X_test, diags_descs_to_tfidf=to_idf)\n",
    "    \"\"\"\n",
    "    diagnosis_descriptions = [\"diag_1_desc\", \"diag_2_desc\", \"diag_3_desc\"]\n",
    "    \n",
    "    if max_df == None:\n",
    "        max_df = int(len(df) * 0.7)\n",
    "      \n",
    "    if diags_descs_to_tfidf == None:\n",
    "        diags_descs_to_tfidf = Pipeline([\n",
    "            (\"select_textual_features\", Selector(diagnosis_descriptions)),\n",
    "            (\"add_missing_class\", MissingChanger(diagnosis_descriptions, \"\")),\n",
    "            (\"tokenize\", TokenizerOur()),\n",
    "            (\"filter_stop_words\", StopWordsFilter()),\n",
    "            (\"perform_stemming\", Stemmer()),\n",
    "            (\"to_string_list\", ToStringList(diagnosis_descriptions)),\n",
    "            # distribution plot of word count revealed that the vast majority of word only \n",
    "            # appears in a very small number of docs, that's why we filter them out\n",
    "            ('vectorizer', TfidfVectorizer(min_df=min_df, max_df=max_df)),\n",
    "        ])\n",
    "        tfidf_out = diags_descs_to_tfidf.fit_transform(df).toarray()\n",
    "    \n",
    "    else:\n",
    "        tfidf_out = diags_descs_to_tfidf.transform(df).toarray()\n",
    "    \n",
    "    for channel in range(tfidf_out.shape[1]):\n",
    "        tfidf_out[:, channel] -= np.mean(tfidf_out[:, channel])\n",
    "        tfidf_out[:, channel] /= np.std(tfidf_out[:, channel])\n",
    "\n",
    "    return tfidf_out, diags_descs_to_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedded_average(df,\n",
    "                         pipeline = textual_preprocessing_pipeline,\n",
    "                         w2v_embedding_size = 30,\n",
    "                         embed_model = None\n",
    "                         ):\n",
    "    \"\"\"\n",
    "    >>> diag_vec_1, diag_vec_2, diag_vec_3, embed_model = get_embedded_average(X_train)\n",
    "    >>> diag_vec_1, diag_vec_2, diag_vec_3, _ = get_embedded_average(X_train, embed_model=embed_model)\n",
    "    \"\"\"\n",
    "    \n",
    "    transformed_text = pipeline.fit_transform(df)\n",
    "    transformed_text_all = np.concatenate([transformed_text[feature].values for feature in diagnosis_descriptions])\n",
    "\n",
    "    if embed_model==None:\n",
    "        embed_model = Word2Vec(transformed_text_all, \n",
    "                               size=w2v_embedding_size,          # Dimensionality of the word vectors.\n",
    "                               min_count=1)        # Ignores all words with total frequency lower than this.\n",
    "\n",
    "    #----------- Initialize 3 embedding matrices for all 3 input variables\n",
    "    df_size = df.shape[0]\n",
    "    problem_words = []\n",
    "    \n",
    "    diag_vec_1 = np.zeros(( df_size, w2v_embedding_size ))\n",
    "    diag_vec_2 = np.zeros(( df_size, w2v_embedding_size ))\n",
    "    diag_vec_3 = np.zeros(( df_size, w2v_embedding_size ))\n",
    "    \n",
    "\n",
    "    for i in range(df_size):\n",
    "        cnt1 = 0\n",
    "        for j in range( len(transformed_text.loc[i, 'diag_1_desc']) ):\n",
    "            try:\n",
    "                cnt1 += 1\n",
    "                diag_vec_1[i, :] += embed_model.wv[transformed_text.loc[i, 'diag_1_desc'][j]]\n",
    "            except Exception as e:  \n",
    "                pass\n",
    "        if cnt1 > 0:\n",
    "            diag_vec_1[i, :] /= cnt1\n",
    "        \n",
    "    for i in range(df_size):\n",
    "        cnt2 = 0\n",
    "        for j in range( len(transformed_text.loc[i, 'diag_2_desc']) ):\n",
    "            try:\n",
    "                cnt2 += 1\n",
    "                diag_vec_2[i, :] += embed_model.wv[transformed_text.loc[i, 'diag_2_desc'][j]]\n",
    "            except Exception as e:  \n",
    "                pass\n",
    "        if cnt2 > 0:\n",
    "            diag_vec_2[i, :] /= cnt2\n",
    "        \n",
    "    for i in range(df_size):\n",
    "        cnt3 = 0\n",
    "        for j in range( len(transformed_text.loc[i, 'diag_3_desc']) ):\n",
    "            try:\n",
    "                cnt3 += 1\n",
    "                diag_vec_3[i, :] += embed_model.wv[transformed_text.loc[i, 'diag_3_desc'][j]]\n",
    "            except Exception as e:  \n",
    "                pass\n",
    "        if cnt3 > 0:\n",
    "            diag_vec_3[i, :] /= cnt3\n",
    "    \n",
    "    assert all(pd.DataFrame(diag_vec_1).isnull().any())==False, \"missing values in representation of diag_vec_1\"\n",
    "    assert all(pd.DataFrame(diag_vec_2).isnull().any())==False, \"missing values in representation of diag_vec_2\"\n",
    "    assert all(pd.DataFrame(diag_vec_3).isnull().any())==False, \"missing values in representation of diag_vec_3\"\n",
    "    \n",
    "    return diag_vec_1, diag_vec_2, diag_vec_3, embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Prepare all input**\n",
    "\n",
    "Transform *training*, *test* and *validation* datasets to the format that can be used by our neural network models. Can pass different functions for text preprocessing as a parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_inputs(df_train, df_val, df_test,\n",
    "\n",
    "                   # list of numeric features\n",
    "                   numerical_features=numerical_features,\n",
    "                   categorical_features=categorical_features,\n",
    "                   medicine_all=medicine_all,\n",
    "                   \n",
    "                   # list of functions for variable transformations.\n",
    "                   # currently only textual input has different types of transformation\n",
    "                   text_func=get_tockenized_sentence, \n",
    "                   \n",
    "                   # list of arguments to the corresponding functions\n",
    "                   args_numeric = {\"sqrt_transform_features\":[]},\n",
    "                   # args_categ,\n",
    "                   args_med = {\"is_binary_output\": True, \"perc_no_values_thresold\": 0.95},\n",
    "                   args_text = {\"num_words_tockenize\": 500,  \"max_sentence_len\": 20, \"w2v_embedding_size\" :30}\n",
    "                  ):\n",
    "    \"\"\"                         \n",
    "    >>> tst = get_all_inputs(X_test, X_test, X_val, text_func=get_tockenized_sentence)\n",
    "    >>> tst = get_all_inputs(X_test, X_test, X_val, text_func=get_embedded_sentence)\n",
    "    >>> tst = get_all_inputs(X_test, X_test, X_val, text_func=get_embedded_average)\n",
    "    \"\"\"\n",
    "    df_train.index = range(len(df_train))\n",
    "    df_val.index = range(len(df_val))\n",
    "    df_test.index = range(len(df_test))\n",
    "\n",
    "    # NUMERIC DATA\n",
    "    numeric_input, normalizer = get_numerical_inputs(df_train, numerical_features=numerical_features, **args_numeric)\n",
    "    numeric_input_val, _ = get_numerical_inputs(df_val, numerical_features=numerical_features, normalizer=normalizer, **args_numeric)\n",
    "    numeric_input_test, _ = get_numerical_inputs(df_test, numerical_features=numerical_features, normalizer=normalizer, **args_numeric)\n",
    "    \n",
    "    assert all([numeric_input.shape[1]==numeric_input_val.shape[1], numeric_input_val.shape[1]==numeric_input_test.shape[1]]), \"problem with numerical input\"\n",
    "\n",
    "    # CATEGORICAL DATA\n",
    "    categ_input, enc = get_categorical_inputs(df_train, categorical_features=categorical_features)\n",
    "    categ_input_val, _ = get_categorical_inputs(df_val, encoder=enc, categorical_features=categorical_features)\n",
    "    categ_input_test, _ = get_categorical_inputs(df_test, encoder=enc, categorical_features=categorical_features)\n",
    "    \n",
    "    assert categ_input.shape[1]==categ_input_val.shape[1] and categ_input_val.shape[1]==categ_input_test.shape[1], \"problem with category input\"\n",
    "\n",
    "    med_input, medicine_to_return, encoder_med = get_medicine_inputs(df_train, medicine_all=medicine_all, **args_med)\n",
    "    med_input_val, _, _ = get_medicine_inputs(df_val, medicine_to_return=medicine_to_return, encoder=encoder_med, medicine_all=medicine_all, **args_med)\n",
    "    med_input_test, _, _ = get_medicine_inputs(df_test, medicine_to_return=medicine_to_return, encoder=encoder_med, medicine_all=medicine_all, **args_med)\n",
    "\n",
    "    assert med_input.shape[1]==med_input_val.shape[1] and med_input_val.shape[1]==med_input_test.shape[1], \"problem with medical input\"\n",
    "    \n",
    "    diag_input = get_diags_inputs(df_train) \n",
    "    diag_input_val = get_diags_inputs(df_val)\n",
    "    diag_input_test = get_diags_inputs(df_test)\n",
    "\n",
    "    assert diag_input.shape[1]==diag_input_val.shape[1] and diag_input_val.shape[1]==diag_input_test.shape[1], \"problem with numerical input\"\n",
    "    \n",
    "    # TEXTUAL DATA\n",
    "    # filter argument list\n",
    "    text_func_args = inspect.getfullargspec(text_func)[0]\n",
    "    args_text = {k:v for k,v in args_text.items() if k in text_func_args}\n",
    "    \n",
    "    if text_func.__name__ == 'get_tockenized_sentence':\n",
    "    \n",
    "        diag1, diag2, diag3, tockinizer_train, vocab_size = text_func( df_train, train=True,  **args_text)\n",
    "        diag1_val, diag2_val, diag3_val, _ , _ = text_func( df_val, train=False, tokenizer=tockinizer_train, **args_text)\n",
    "        diag1_test, diag2_test, diag3_test, _ ,_ = text_func( df_test, train=False, tokenizer=tockinizer_train, **args_text)\n",
    "    \n",
    "    elif text_func.__name__ in ['get_embedded_sentence','get_embedded_average']:\n",
    "        \n",
    "        diag1, diag2, diag3, embed_model = text_func(df_train, **args_text)\n",
    "        diag1_val, diag2_val, diag3_val, _ = text_func(df_val, embed_model=embed_model, **args_text)\n",
    "        diag1_test, diag2_test, diag3_test, _ = text_func(df_test, embed_model=embed_model, **args_text)\n",
    "        vocab_size = None\n",
    "\n",
    "    elif text_func.__name__ == 'get_diags_descs_tfidf':\n",
    "        \n",
    "        print(\"Not implemented yet\")\n",
    "        raise Exception\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        print(\"Unknonw text preprocessing function type\")\n",
    "        raise Exception\n",
    "        \n",
    "    assert diag1.shape[1]==diag1_val.shape[1] and diag1_val.shape[1]==diag1_test.shape[1], \"problem with diag1 input: {} {} {}\".format(diag1.shape[1], diag2.shape[1], diag3.shape[1])\n",
    "\n",
    "    # GET DIMENSIONALITY OF INPUTS\n",
    "    \n",
    "    neurons_numerical = numeric_input.shape[1]\n",
    "    neurons_categorical = categ_input.shape[1]\n",
    "    neurons_medicine = med_input.shape[1]\n",
    "    neurons_diags = diag_input.shape[1]\n",
    "    neurons_diags_descs = diag1.shape[1]\n",
    "\n",
    "    all_inputs = [diag1, diag2, diag3, numeric_input, med_input, categ_input, diag_input] #np.concatenate((numerical_inputs, categorical_inputs, medicine_inputs, diags_inputs, diags_descs), axis=1)\n",
    "    all_inputs_val = [diag1_val, diag2_val, diag3_val, numeric_input_val, med_input_val, categ_input_val, diag_input_val] #np.concatenate((numerical_inputs, categorical_inputs, medicine_inputs, diags_inputs, diags_descs), axis=1)\n",
    "    all_inputs_test = [diag1_test, diag2_test, diag3_test, numeric_input_test, med_input_test, categ_input_test, diag_input_test] #np.concatenate((numerical_inputs, categorical_inputs, medicine_inputs, diags_inputs, diags_descs), axis=1)\n",
    "    \n",
    "    input_dimensions = (neurons_numerical, neurons_categorical, neurons_medicine, neurons_diags, neurons_diags_descs)\n",
    "    \n",
    "    return all_inputs, all_inputs_val, all_inputs_test, input_dimensions, vocab_size\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Single Model Development**\n",
    "\n",
    "In this subsection we will present models for separately preprocessing different groups of input variables. Originally we were planning on created different model architectures for different groups of variables, however it would further unnecessarily increase the hyperparameter space, thus we will divide the variables into just two groups: *textual* and *non-textual*\n",
    "\n",
    "\n",
    "**Note:** when it comes to categorical variables, it might make sence to create separate models for certain variables and not mix them all together. More precisely, we can use *word embedding* or *tf-idf* to preprocess variables such as `\"discharge_disposition_id` and `medical_specialty`. However due to time constraints we might postpone it for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One model for all non-textual inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_textual_features(inp_dim,\n",
    "                             debug=False,\n",
    "                             **archit_params):\n",
    "    \"\"\"\n",
    "    >>> get_diags_3_inp = get_non_textual_features(X_train)\n",
    "    \"\"\"\n",
    "    \n",
    "    diag_inp = Input(shape=(inp_dim, ))\n",
    "\n",
    "    hidden_unit = archit_params.get(\"hidden_unit\", int(inp_dim/4) + 1)\n",
    "    activation_func = archit_params.get(\"activation\", 'relu')\n",
    "    \n",
    "    hidden1 = Dense(hidden_unit, activation=activation_func, kernel_regularizer=regularizers.l2(0.004))(diag_inp)\n",
    "        \n",
    "    hidden_unit = 1 if debug else hidden_unit  # hidden_unit\n",
    "    out_diag = Dense(hidden_unit, activation=activation_func)(hidden1)\n",
    "    \n",
    "    model = Model(inputs=diag_inp, outputs=out_diag)\n",
    "    \n",
    "    return model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Textual input: models** \n",
    "\n",
    "We currently consider three types of models:\n",
    "\n",
    "* every sentence is a tockenized and encoded with length at most `max_len` (get_model_lstm_own_embedding)\n",
    "* every sentence is represented by a matrix with dimension `max_len` x `embedding_size`. This representation can be obtained by i.e. **Word2Vec** (get_model_lstm_embedding_ready)\n",
    "* every sentence is represented by a vector of a fixed (?) size. This representation can be obtained by i.e. **tf-idf** or **word2doc** (get_model_tfdif)\n",
    "\n",
    "Another question is how do we combine the information from `diag_1_desc`, `diag_2_desc` and `diag_3_desc`. Between **a)** concatenate and preprocess **b)** preprocess separately and combine high level representation, we select **b)** (see get_multimodel_lstm). However our framework can be easily adapted for **a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_lstm_own_embedding( text_inp_len, \n",
    "                                  #vocab_size=vocab_size, \n",
    "                                  #embedding_size=embedding_size_lstm,\n",
    "                                  lstm_units=16,#lstm_units_intern,\n",
    "                                  dense_units=16,#dense_units_lstm,\n",
    "                                  debug=False,\n",
    "                                  **lstm_args\n",
    "                                ):\n",
    "    \"\"\"\n",
    "    input is a tockenized sentence\n",
    "    \n",
    "    :param max_len: maximum length of the input sentence\n",
    "    :param vocab_size: number of preserved words\n",
    "    \"\"\"\n",
    "    visible = Input(shape=(text_inp_len, ))\n",
    "\n",
    "    emb = Embedding(vocab_size, embedding_size, input_length=text_inp_len)(visible)\n",
    "    hidden1 = LSTM(lstm_units, activation=lstm_args.get(\"activation_1\", \"relu\"))(emb) # Bidirectional(\n",
    "    \n",
    "    dense_units = 1 if debug else dense_units  \n",
    "    hidden1 = Dense(dense_units, activation=lstm_args.get(\"activation_2\", \"relu\"))(hidden1)\n",
    "    output = Dense(dense_units, activation=lstm_args.get(\"activation_3\", \"relu\"))(hidden1)\n",
    "    \n",
    "    model = Model(inputs=visible, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_model_lstm_embedding_ready( max_len, \n",
    "                                    w2v_embedding_size=30,\n",
    "                                    lstm_units=64,\n",
    "                                    dense_units=32\n",
    "                                   ):\n",
    "    \"\"\"\n",
    "    input sentence is already embedded using some procedure, e.g. word3vec\n",
    "    \n",
    "    :param max_len: maximum length of the input sentence\n",
    "    :param vocab_size: number of preserved words\n",
    "\n",
    "    \"\"\"\n",
    "    emb = Input(shape=(max_len, w2v_embedding_size, ))  # this order ?\n",
    "    \n",
    "    hidden1 = LSTM(lstm_units)(emb)  \n",
    "    output  = Dense(1, activation='relu')(hidden1)\n",
    "    \n",
    "    model   = Model(inputs=emb, outputs=output)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def get_model_average_w2v( represent_len,\n",
    "                           debug=False,\n",
    "                           **average_w2v_args):\n",
    "    \"\"\"\n",
    "    sentence is represented by a single vector of a fixed sise = `represent_len`\n",
    "    \"\"\"\n",
    "    inp_repr = Input(shape=(represent_len, ))  # this order ?\n",
    "    \n",
    "    activation_func = average_w2v_args.get(\"activation\", \"relu\")\n",
    "    hidden_unit = average_w2v_args.get(\"hidden_unit\", 10)\n",
    "    \n",
    "    hidden_unit = 1 if debug else hidden_unit  # hidden_unit\n",
    "    output = Dense(hidden_unit, activation=activation_func)(inp_repr)\n",
    "    \n",
    "    model = Model(inputs=inp_repr, outputs=output)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Multi Input Model**\n",
    "\n",
    "Here we combine all components from the previous subsections to get multi input model. \n",
    "\n",
    "\n",
    "**Comment** The following links helped us to write the code for this section: [link1](https://www.pyimagesearch.com/2019/02/04/keras-multiple-inputs-and-mixed-data/), [link2](https://heartbeat.fritz.ai/building-a-mixed-data-neural-network-in-keras-to-predict-accident-locations-d51a63b738cf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_multimodel(\n",
    "                        # input dimensions\n",
    "                        text_inp_len, num_pred_len, num_of_treatments, cat_features_shape, diag_code_dim,\n",
    "                        \n",
    "                        # functions for individual models\n",
    "                        text_nn_model = get_model_lstm_own_embedding,\n",
    "    \n",
    "                        # (hyper) parameters for individual models\n",
    "                        general_args = {\"vocab_size\": 500, \"learning_rate_adam\":0.002}, # vocab_size\n",
    "                        model_numeric_args = {\"activation\": 'tahn'},\n",
    "                        medical_args = {\"hidden_unit\":2},\n",
    "                        categ_args ={\"hidden_unit\":3},\n",
    "                        model_text_args = {\"embedding_size\":10, \"lstm_units\":32, \"dense_units\": 32},\n",
    "                        model_out_args = {\"dense_out_1\":128, \"dense_out_2\":128}\n",
    "                       ):\n",
    "\n",
    "    # DIAGNOSIS: TEXTUAL ------------------------------------------\n",
    "    text_nn_model_args = inspect.getfullargspec(text_nn_model)[0]\n",
    "    model_text_args = {k:v for k,v in model_text_args.items() if k in text_nn_model_args}\n",
    "    \n",
    "    if text_nn_model.__name__ == 'get_model_lstm_own_embedding':\n",
    "    \n",
    "        nlp_out_diag1 = text_nn_model(text_inp_len, vocab_size=general_args.get(\"vocab_size\"), **model_text_args)\n",
    "        nlp_out_diag2 = text_nn_model(text_inp_len, vocab_size=general_args.get(\"vocab_size\"), **model_text_args)\n",
    "        nlp_out_diag3 = text_nn_model(text_inp_len, vocab_size=general_args.get(\"vocab_size\"), **model_text_args)\n",
    "        \n",
    "    elif text_nn_model.__name__ == 'get_model_lstm_embedding_ready':\n",
    "        \n",
    "        embedding_size = model_text_args.get(\"w2v_embedding_size\", 30) \n",
    "        \n",
    "        nlp_out_diag1 = text_nn_model(text_inp_len, **model_text_args)\n",
    "        nlp_out_diag2 = text_nn_model(text_inp_len, **model_text_args)\n",
    "        nlp_out_diag3 = text_nn_model(text_inp_len, **model_text_args)\n",
    "    \n",
    "    elif text_nn_model.__name__ == 'get_model_average_w2v':\n",
    "        \n",
    "        nlp_out_diag1 = text_nn_model(text_inp_len, **model_text_args)\n",
    "        nlp_out_diag2 = text_nn_model(text_inp_len, **model_text_args)\n",
    "        nlp_out_diag3 = text_nn_model(text_inp_len, **model_text_args)\n",
    "\n",
    "    else:\n",
    "        prin(\"Models with tf-idf representation are trained in models_final.ipynb\")\n",
    "        raise Exception\n",
    "        \n",
    "    nlp_out = keras.layers.concatenate([nlp_out_diag1.output, \n",
    "                                        nlp_out_diag2.output,\n",
    "                                        nlp_out_diag3.output])\n",
    "    \n",
    "    nlp_out = Dense(16, activation='relu')(nlp_out)\n",
    "    nlp_out = Dropout(0.2)(nlp_out)                                       # Add dropout layer\n",
    "    \n",
    "    \n",
    "    # Numeric Variables -------------------------------------------\n",
    "    numeric_out = get_non_textual_features(num_pred_len, **model_numeric_args) #  \"activation\", \"hidden_unit\") #get_numeric_model_1(num_pred_len, **model_numeric_args) #Input(shape=(10, ))\n",
    "    \n",
    "    # Categorical Variables ---------------------------------------\n",
    "    medic_out = get_non_textual_features(num_of_treatments, **medical_args) #get_medication_model_1(num_of_treatments, **medical_args)\n",
    "    categ_out = get_non_textual_features(cat_features_shape, **categ_args)  #get_categorical_model_1(cat_features_shape, **categ_args) \n",
    "    diag_out =  get_non_textual_features(diag_code_dim)                     #get_diags_code_model_1(diag_code_dim)\n",
    "    \n",
    "    \n",
    "    # Combined model ----------------------------------------------\n",
    "    x = keras.layers.concatenate([nlp_out, numeric_out.output, \n",
    "                                  medic_out.output, categ_out.output, \n",
    "                                  diag_out.output]) # , medic_out.output\n",
    "    \n",
    "    x = Dense( model_out_args.get(\"dense_out_1\", 64), kernel_regularizer=regularizers.l2(0.004), \n",
    "               activation=model_out_args.get(\"activ_out_1\", 'relu') )(x)\n",
    "    x = Dropout(0.2)(x)    \n",
    "    x = Dense( model_out_args.get(\"dense_out_2\", 64), # kernel_regularizer=regularizers.l2(0.004), \n",
    "               activation=model_out_args.get(\"activ_out_1\", 'relu') )(x)\n",
    "    x = Dense(1, activation=model_out_args.get(\"activ_out_2\", 'sigmoid') )(x)\n",
    "\n",
    "    input_list = [nlp_out_diag1.input, nlp_out_diag2.input, nlp_out_diag3.input, \n",
    "                  numeric_out.input, medic_out.input, \n",
    "                  categ_out.input, diag_out.input]\n",
    "    \n",
    "    model = Model(inputs=input_list, outputs=[x])\n",
    "    \n",
    "    model.compile(loss=keras.losses.binary_crossentropy, #keras.losses.binary_crossentropy,\n",
    "                    optimizer=keras.optimizers.Adam(lr=general_args.get(\"learning_rate_adam\", 0.002)  ), # lr=0.002\n",
    "                    metrics=['acc'])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Hyperparameter tuning**\n",
    "\n",
    "Here we set up the pipeline, that enables us to easily experiment with different hyper parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path_multi = \"multi_input_mlp_tuning.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path_multi, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1000, verbose=0)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, factor=0.5, verbose=0)\n",
    "callbacks_list = [checkpoint, early, redonplat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We starting from data loading. Important choices at this point:\n",
    "\n",
    "1. to balance or not to balance the dataset?\n",
    "2. combine or not to combine train and validation dataset to increase the number of training examples\n",
    "3. perform or not to perform certain steps of the preprocessing\n",
    "    * encode certain values as missing variables?\n",
    "    * whiche variables should be reencoded / imputed ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_delete = [\"weight\", \"max_glu_serum\", \"A1Cresult\"]\n",
    "\n",
    "vars_to_reencode =  [\"payer_code\", \"medical_specialty\", \"discharge_disposition_id\", \n",
    "                     \"diag_1_desc\", \"diag_2_desc\", \"diag_3_desc\"]\n",
    "\n",
    "vars_to_impute = [\"admission_type_id\", \"admission_source_id\", \"race\"]\n",
    "\n",
    "missing_symbols = ['?', 'None','Not Available', 'Not Mapped']\n",
    "\n",
    "\n",
    "data_inp = data_loading_preprocessing(balance_data = False,\n",
    "                               combine_train_and_val = False,\n",
    "                               encode_as_missing = True,\n",
    "                               missing_symbols = missing_symbols,\n",
    "                               vars_to_delete = vars_to_delete,\n",
    "                               vars_to_reencode = vars_to_reencode,\n",
    "                               vars_to_impute = vars_to_impute )\n",
    "    \n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data_inp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we prepare the input for our Deep learning models. Our options include:\n",
    "\n",
    "1. use `age` or `age_category` in the subsequent analysis\n",
    "2. how to do the text embedding\n",
    "3. how to encode/preprocess variables related to medical treatments\n",
    "4. perform or not perform a sqrt transformation on the certain numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 drugs left (out of 23) after filtering with threshold 0.95: \n",
      "\n",
      "\n",
      "Variables used:\n",
      "------------------------\n",
      "Categorical: 8\n",
      "Medical: 23\n",
      "Numerical: 10\n",
      "------------------------\n",
      "\n",
      "Input dimensionality:\n",
      "------------------------\n",
      "Diagnosis embedding: 50\n",
      "Numeric input: 10\n",
      "Categorical input: 90\n",
      "Diagnosis codes: 17\n",
      "Medication-related: 17\n",
      "------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "numerical_features = [\"time_in_hospital\", \"num_procedures\", \n",
    "                      \"number_outpatient\", \"number_emergency\", \n",
    "                      \n",
    "                       # add integer encoded ordinal variables\n",
    "                      \"age_category\", \"admission_type_id_category\",\n",
    "                      \n",
    "                      \"number_inpatient\", \"number_diagnoses\",\n",
    "                      \"num_medications\", \"num_lab_procedures\"]\n",
    "\n",
    "categorical_features = [\"race\", \"gender\", \n",
    "                        \n",
    "                        #\"age\",  \"admission_type_id\",       # used in the model as age_category and  admission_type_id_category\n",
    "                        #\"max_glu_serum\", \"A1Cresult\",      # delete due too many missing variables\n",
    "                        \"payer_code\", \"medical_specialty\",  # a lot of missing values, exclude?\n",
    "                        \n",
    "                        \"change\", \"diabetesMed\", \n",
    "                        \"admission_source_id\", \n",
    "                        \"discharge_disposition_id\"]\n",
    "    \n",
    "medicine_all = [\"metformin\", \"repaglinide\", \"nateglinide\", \"chlorpropamide\", \"glimepiride\", \n",
    "                \"acetohexamide\", \"glipizide\", \"glyburide\", \"tolbutamide\", \"pioglitazone\", \"rosiglitazone\", \n",
    "                \"acarbose\", \"miglitol\", \"troglitazone\", \"tolazamide\", \"examide\", \"citoglipton\", \"insulin\", \n",
    "                \"glyburide.metformin\", \"glipizide.metformin\", \"glimepiride.pioglitazone\", \n",
    "                \"metformin.rosiglitazone\", \"metformin.pioglitazone\"]\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "W2V_EMBED_SIZE = 50\n",
    "\n",
    "inp_all_info = get_all_inputs(X_train, X_test, X_val,\n",
    "                              \n",
    "                              # Type of function to preprocess data\n",
    "                              #text_func=get_tockenized_sentence,  \n",
    "                              #text_func=get_embedded_sentence,\n",
    "                              text_func=get_embedded_average,\n",
    "                              \n",
    "                              # Variables in different groups\n",
    "                              numerical_features=numerical_features,\n",
    "                              categorical_features=categorical_features,\n",
    "                              medicine_all=medicine_all,\n",
    "                              \n",
    "                              # Arguments to different data preprocessing functions\n",
    "                              args_numeric = {\"sqrt_transform_features\":['number_outpatient', 'number_emergency', 'number_inpatient']},\n",
    "                              \n",
    "                              args_med = {\"is_binary_output\": True, \"perc_no_values_thresold\": 0.95},\n",
    "                              \n",
    "                              args_text = {\"num_words_tockenize\": 500,  \n",
    "                                           \"max_sentence_len\": 20, \n",
    "                                           \"w2v_embedding_size\": W2V_EMBED_SIZE}\n",
    "                              )\n",
    "\n",
    "all_inputs, all_inputs_val, all_inputs_test, input_dimensions, vocab_size = inp_all_info\n",
    "num_pred_len, cat_features_shape, num_of_treatments, diag_code_dim, text_inp_len = input_dimensions \n",
    "\n",
    "\n",
    "print(\"\\nVariables used:\\n------------------------\\nCategorical: {}\\nMedical: {}\\nNumerical: {}\\n------------------------\".format(len(categorical_features), len(medicine_all), len(numerical_features)))\n",
    "print(\"\\nInput dimensionality:\\n------------------------\\nDiagnosis embedding: {}\\nNumeric input: {}\\nCategorical input: {}\\nDiagnosis codes: {}\\nMedication-related: {}\\n------------------------\\n\".format(text_inp_len, num_pred_len, cat_features_shape, diag_code_dim, diag_code_dim)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this part we can specify and adjust different parameters of the model architectures defined in previous subsections, such as:\n",
    "\n",
    "1. number of layers\n",
    "2. number of neurons in a layer\n",
    "3. activations used for certain layers\n",
    "\n",
    "**Note**: changing the neural network model, required rewrunning the previous cell with data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is:  0.4948419841801346\n",
      "ACC score is:  0.5395\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# General training controllers\n",
    "epoch_number = 60    # learning seems to stabilize at this point\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "multi_model =  get_multimodel(\n",
    "                        \n",
    "                        text_inp_len, num_pred_len, num_of_treatments, cat_features_shape, diag_code_dim, \n",
    "                        \n",
    "                        # MODELS to process textual data. \n",
    "                        # NOTE: If changin the model, need to change the input in the previous cell accordingly\n",
    "                        #text_nn_model = get_model_lstm_own_embedding,\n",
    "                        #text_nn_model = get_model_lstm_embedding_ready, # get_model_lstm_own_embedding, # 'get_model_lstm_embedding_ready'\n",
    "                        text_nn_model = get_model_average_w2v,\n",
    "    \n",
    "                        # Hyper parameters of individual models\n",
    "                        general_args = {\"vocab_size\": vocab_size, \"learning_rate_adam\": 0.01 },\n",
    "                        \n",
    "                        model_numeric_args = {\"hidden_unit\": 3, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        medical_args = {\"hidden_unit\":2, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        categ_args = {\"hidden_unit\":3, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        model_text_args = {\"embedding_size\": 10, \n",
    "                                           \"lstm_units\": 16, \n",
    "                                           \"w2v_embedding_size\": W2V_EMBED_SIZE,    \n",
    "                                           \"dense_units\": 16, \"activation\":'tanh',\n",
    "                                           \"activation_2\" : \"relu\" },\n",
    "                        \n",
    "                        model_out_args = {\"dense_out_1\": 16, \"dense_out_2\": 16}\n",
    "    \n",
    "                       )\n",
    "\n",
    "#print(multi_model.summary())\n",
    "\n",
    "\n",
    "history = multi_model.fit(all_inputs, Y_train,\n",
    "                          epochs=epoch_number,\n",
    "                          batch_size=128,\n",
    "                          verbose=0,\n",
    "                          callbacks=callbacks_list,\n",
    "                          validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#--------------- Training Histroy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#--------------- MODEL EVALUATION ON THE VALIDATION SET\n",
    "y_pred_val = multi_model.predict(all_inputs_val)\n",
    "\n",
    "print(\"AUC score is: \", metrics.roc_auc_score(Y_val, y_pred_val))\n",
    "y_pred_val = (y_pred_val > 0.5).astype(np.int8)\n",
    "print(\"ACC score is: \", metrics.accuracy_score(Y_val, y_pred_val))\n",
    "\n",
    "#--------------- CONFUSION MATRIX (important since imbalanced)\n",
    "cf_matrix = confusion_matrix(Y_val, y_pred_val)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Experiments**\n",
    "\n",
    "The number of hyper parameters for our model is quite big, so a grid search would have taken too much time. We have decided insted, to concentrate on the few parameters and look at their impact on the prediction results. The parameters in question are: *type of the textual preprocessing model*, *w2v embedding size* and *number of the dense units* in the get_multimod() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "1. get_model_lstm_own_embedding seems to perform slightly worse than models with the **word2vec** embeddings. \n",
    "2. increasing embedding size for **word2vec** seems to slightly improve the predictions\n",
    "3. increasing the number of lstm units from 16 to 32 does not seem to help a lot\n",
    "4. decreasing the number of dense units decreases performance a bit.\n",
    "\n",
    "**Miscellaneous**\n",
    "1. models using `age category` slightly outperform the models with `age`\n",
    "2. not balancing the dataset produces better results in terms of Accuracy score, since the distribution of positive and negative examples is the same accross *training*, *test* and *validation* datasets\n",
    "3. due to the fact that our dataset is small, need to try to decrease the number of weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final model**\n",
    "\n",
    "We retrain one of the promising models discovered during the hyperparameter tuning on *training* and *val* dataset and evaluate its performance on *test* dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 drugs left (out of 23) after filtering with threshold 0.95: \n",
      "\n",
      "Model: \"model_16\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_9 (InputLayer)            (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_10 (InputLayer)           (None, 30)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 10)           310         input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 10)           310         input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 10)           310         input_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 30)           0           dense_16[0][0]                   \n",
      "                                                                 dense_17[0][0]                   \n",
      "                                                                 dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "input_11 (InputLayer)           (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 90)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_14 (InputLayer)           (None, 17)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16)           496         concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 2)            22          input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 2)            14          input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 2)            182         input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 5)            90          input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16)           0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 2)            6           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 2)            6           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 2)            6           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 5)            30          dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 27)           0           dropout_3[0][0]                  \n",
      "                                                                 dense_21[0][0]                   \n",
      "                                                                 dense_23[0][0]                   \n",
      "                                                                 dense_25[0][0]                   \n",
      "                                                                 dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 16)           448         concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16)           0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 16)           272         dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 1)            17          dense_29[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,519\n",
      "Trainable params: 2,519\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is:  0.6120011367067474\n",
      "ACC score is:  0.6515\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_path_multi = \"multi_input_mlp_final.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path_multi, monitor='val_acc', verbose=0, save_best_only=True, mode='max')\n",
    "early = EarlyStopping(monitor=\"val_acc\", mode=\"max\", patience=1000, verbose=0)\n",
    "redonplat = ReduceLROnPlateau(monitor=\"val_acc\", mode=\"max\", patience=5, factor=0.5, verbose=0)\n",
    "callbacks_list = [checkpoint, early, redonplat]\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "W2V_EMBED_SIZE = 30\n",
    "epoch_number = 100  # learning seems to stabilize at this point\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "data_inp = data_loading_preprocessing(balance_data = True,\n",
    "                               combine_train_and_val = True,\n",
    "                               encode_as_missing = True,\n",
    "                               missing_symbols = missing_symbols,\n",
    "                               vars_to_delete = vars_to_delete,\n",
    "                               vars_to_reencode = vars_to_reencode,\n",
    "                               vars_to_impute = vars_to_impute )\n",
    "    \n",
    "X_train, Y_train, X_val, Y_val, X_test, Y_test = data_inp\n",
    "\n",
    "\n",
    "inp_all_info = get_all_inputs(X_train, X_test, X_val,\n",
    "                              \n",
    "                              # Type of function to preprocess data\n",
    "                              text_func=get_embedded_average,\n",
    "                              \n",
    "                              # Variables in different groups\n",
    "                              numerical_features=numerical_features,\n",
    "                              categorical_features=categorical_features,\n",
    "                              medicine_all=medicine_all,\n",
    "                              \n",
    "                              # Arguments to different data preprocessing functions\n",
    "                              args_numeric = {\"sqrt_transform_features\":['number_outpatient', 'number_emergency', 'number_inpatient']},\n",
    "                              \n",
    "                              args_med = {\"is_binary_output\": True, \"perc_no_values_thresold\": 0.95},\n",
    "                              \n",
    "                              args_text = {\"num_words_tockenize\": 500,  \n",
    "                                           \"max_sentence_len\": 20, \n",
    "                                           \"w2v_embedding_size\": W2V_EMBED_SIZE}\n",
    "                              )\n",
    "\n",
    "all_inputs, all_inputs_val, all_inputs_test, input_dimensions, vocab_size = inp_all_info\n",
    "num_pred_len, cat_features_shape, num_of_treatments, diag_code_dim, text_inp_len = input_dimensions\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "multi_model =  get_multimodel(\n",
    "                        \n",
    "                        text_inp_len, num_pred_len, num_of_treatments, cat_features_shape, diag_code_dim, \n",
    "                        \n",
    "                        # MODELS to process textual data. \n",
    "                        text_nn_model = get_model_average_w2v,\n",
    "    \n",
    "                        # Hyper parameters of individual models\n",
    "                        general_args = {\"vocab_size\": vocab_size, \"learning_rate_adam\": 0.01 },\n",
    "                        \n",
    "                        model_numeric_args = {\"hidden_unit\": 2, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        medical_args = {\"hidden_unit\": 2, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        categ_args = {\"hidden_unit\": 2, \"activation\": 'tanh'},\n",
    "                        \n",
    "                        model_text_args = {\"embedding_size\": 10, \n",
    "                                           \"lstm_units\": 8, \n",
    "                                           \"w2v_embedding_size\": W2V_EMBED_SIZE,    \n",
    "                                           \"dense_units\": 8, \"activation\":'tanh',\n",
    "                                           \"activation_2\" : \"relu\" },\n",
    "                        \n",
    "                        model_out_args = {\"dense_out_1\": 16, \"dense_out_2\": 16}\n",
    "    \n",
    "                       )\n",
    "\n",
    "print(multi_model.summary())\n",
    "\n",
    "\n",
    "history = multi_model.fit(all_inputs, Y_train,\n",
    "                          epochs=epoch_number,\n",
    "                          batch_size=128,\n",
    "                          verbose=0,\n",
    "                          callbacks=callbacks_list,\n",
    "                          validation_split=0.1)\n",
    "\n",
    "\n",
    "\n",
    "#--------------- Training Histroy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model acc')\n",
    "plt.ylabel('acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#--------------- MODEL EVALUATION ON THE TEST SET\n",
    "y_pred_test = multi_model.predict(all_inputs_test)\n",
    "y_pred_test = (y_pred_val > 0.5).astype(np.int8)\n",
    "\n",
    "print(\"AUC score is: \", metrics.roc_auc_score(Y_test, y_pred_test))\n",
    "y_pred_test = (y_pred_test > 0.5).astype(np.int8)\n",
    "print(\"ACC score is: \", metrics.accuracy_score(Y_test, y_pred_test))\n",
    "\n",
    "#--------------- CONFUSION MATRIX (important since imbalanced)\n",
    "cf_matrix = confusion_matrix(Y_test, y_pred_test)\n",
    "sns.heatmap(cf_matrix, annot=True, fmt='g')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we have experimented with different architectures and different text representation methods. These experiments did not result in a better model than the model developed in `models.ipynb` however maybe this architecture could have certain potential for making the prediction on a full dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
